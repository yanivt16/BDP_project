{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "T7ouxD3obf9O",
        "qP-tclhENY_K",
        "J4Zz9RDQmPUO",
        "DlX48EsljI-f",
        "iYrsXJVZqdsQ",
        "YT-ceD4JsDll",
        "p8SF5yQ1gdn-"
      ],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanivt16/BDP_project/blob/main/Police_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "dqZcndSSjtkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -O ./spark-3.3.1-bin-hadoop3.tgz  https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar zxvf ./spark-3.3.1-bin-hadoop3.tgz \n",
        "!pip install findspark "
      ],
      "metadata": {
        "id": "us9wYFRtjwvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "2Fre6_SsjwrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "import random\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "JWpGM95bj25y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('lr_example').getOrCreate()"
      ],
      "metadata": {
        "id": "zSq4H5o7Y5X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pyspark\n",
        "from pyspark.rdd import RDD\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, IntegerType, StringType\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.functions import substring, when, concat, lit, col, to_date, regexp_replace, udf\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") #Ignores all unfamiliar fonts\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (15,7)\n",
        "\n",
        "import datetime"
      ],
      "metadata": {
        "id": "IDexHskEgkky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "NFLD1VuQ-ixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gtQsT66-xZNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_pd = pd.read_csv('/content/drive/MyDrive/BDP_Project/-3-2022-.csv')"
      ],
      "metadata": {
        "id": "WVXB3iTt4H43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translate Data"
      ],
      "metadata": {
        "id": "sIp03wWjN2mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install googletrans==4.0.0rc1 gwpy &> /dev/null"
      ],
      "metadata": {
        "id": "MFYmGojeN8xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from googletrans import Translator\n",
        "# translator = Translator()"
      ],
      "metadata": {
        "id": "xZwTFY1eQbDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def translate_column (df:pd.DataFrame, name:str):\n",
        "#   y = 'he_' + name\n",
        "#   column_to_translate = pd.DataFrame(list(df[name].unique())).rename({0:y},axis=1)\n",
        "#   x = 'en_' + name\n",
        "#   column_to_translate[x] = column_to_translate[y].apply(lambda x: translator.translate(x, src='he', dest='en').text)\n",
        "#   df = df.merge(column_to_translate, left_on=name, right_on=y,how ='inner')\n",
        "#   df[name]=df[x]\n",
        "#   df=df.drop(columns=[x,y])\n",
        "#   return df"
      ],
      "metadata": {
        "id": "Ouu10Xk23lov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en_df_pd = df_pd\n",
        "# column_names = en_df_pd.columns\n",
        "# k = column_names.delete([4,5,6,9])\n",
        "# for i in k:\n",
        "#   en_df_pd = translate_column(en_df_pd,i)\n",
        "# en_df_pd"
      ],
      "metadata": {
        "id": "gGEmIX9LEb1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en_df_pd.to_csv('/content/drive/MyDrive/BDP_Project/en_df_pd.csv', index=False)"
      ],
      "metadata": {
        "id": "SxSXdTGq4Vld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Spark-DF and Clening Data"
      ],
      "metadata": {
        "id": "VXhwSQOybU9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkByExamples.com\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "E7edW8jm1acU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = spark.read.parquet(\"/content/drive/MyDrive/BDP_Project/en_df_pd.parquet\")\n",
        "# #df = spark.createDataFrame(en_df_pd.astype(str))\n",
        "# df.printSchema()\n",
        "# df.show(5)"
      ],
      "metadata": {
        "id": "lhun1Dw6c4fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.withColumn('PoliceDistrict', regexp_replace('PoliceDistrict', 'Cell County', 'Tel Aviv District'))\n",
        "# df = df.withColumn('PoliceDistrict', regexp_replace('PoliceDistrict', 'Shay County', 'Judea and Samaria District'))"
      ],
      "metadata": {
        "id": "C54w3Y26j0X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.select('PoliceDistrict').distinct().collect() #this is the way how to know how many unique value in the attribute"
      ],
      "metadata": {
        "id": "Fezu4NDjmRdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df1 = df.withColumn(\"TikimSum\",df.TikimSum.cast('int'))"
      ],
      "metadata": {
        "id": "d1uTqoZ2ukiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df2 = df1.withColumn('year', substring('Quarter', 1,4))\\\n",
        "#     .withColumn('Q', substring('Quarter', 6,2))\n",
        "# df2.printSchema()\n",
        "# df2.show(truncate=False)"
      ],
      "metadata": {
        "id": "MVVcA_rj2-Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df2 = df2.withColumn(\"year\",df2.year.cast(StringType()))"
      ],
      "metadata": {
        "id": "Ua3Z4I9q-ntR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df3 = df2.withColumn(\"date\", \\\n",
        "#    when((df2.Q == 'Q2'), lit(\"-30-06\"))\\\n",
        "#    .when((df2.Q == 'Q3'), lit(\"-30-09\"))\\\n",
        "#    .when((df2.Q == 'Q4'), lit(\"-31-12\"))\\\n",
        "#    .otherwise(lit(\"-31-03\")) \\\n",
        "#   )"
      ],
      "metadata": {
        "id": "HQmVydi-89rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df3.show(5)"
      ],
      "metadata": {
        "id": "u1wdycgZAVsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # df_date = df3.select(concat('year','date').alias(\"Exact Date\"))\n",
        "# df3 = df3.withColumn(\"Exact Date\", concat('year','date'))\n",
        "# df3.show(5)"
      ],
      "metadata": {
        "id": "jyWmBiXbUokh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df3 = df3.withColumn(\"Date Value\", to_date(df3['Exact Date'], \"yyyy-dd-MM\"))"
      ],
      "metadata": {
        "id": "J2zDOdgQNmwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df3.show(5)\n",
        "# df3.printSchema()"
      ],
      "metadata": {
        "id": "sAxZ-TZwNzr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df5 = df4.join(socio_economic_df, on='Settlement_Council', how='left')"
      ],
      "metadata": {
        "id": "n4zv6lM-Ki30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.select('PoliceDistrict').distinct().collect() #this is the way how to know how many unique value in the attribute"
      ],
      "metadata": {
        "id": "z74gUupTsll3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citydata = spark.read.csv(\"/content/drive/MyDrive/BDP_Project/city_data.csv\",inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "6tpIBEtOyqtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "citydata = citydata.withColumnRenamed(\"שם יישוב\",\"Settlement_Council\")\n",
        "citydata = citydata.withColumnRenamed(\"סך הכל אוכלוסייה 2021\",\"Population\")\n",
        "citydata = citydata.withColumnRenamed(\"תעתיק\" , \"City Name\")"
      ],
      "metadata": {
        "id": "xcdHlnBOxDSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_df = citydata.select(\"Settlement_Council\", \"Population\",\"City Name\" )"
      ],
      "metadata": {
        "id": "XvdJ3KwB26gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Join the selected columns from city_df with crimes_df on the 'city_name' column\n",
        "# df4 = df3.join(city_df, on='Settlement_Council', how='left')"
      ],
      "metadata": {
        "id": "oIPmsFpjxWqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df4.show(5)"
      ],
      "metadata": {
        "id": "ZFBijiAHz8oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# socio_economic_df = spark.read.csv(\"/content/drive/MyDrive/BDP_Project/s_e_2019.csv\",inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "qS-APerPzUQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# socio_economic_df.show(5)"
      ],
      "metadata": {
        "id": "sRk7LkoU2A68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# socio_economic_df = socio_economic_df.select(col(\"Settlement_Council\"), col(\"City_Cluster_2019\"))\n",
        "\n",
        "# # Join the selected columns from city_df with crimes_df on the 'city_name' column\n",
        "# df5 = df4.join(socio_economic_df, on='Settlement_Council', how='left')"
      ],
      "metadata": {
        "id": "v65gXa382Rhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df5 = df5.withColumnRenamed(\"Settlement_Council\", \"Settlement_Council_Hebrew\")\n",
        "# df5 = df5.withColumnRenamed(\"City Name\", \"Settlement_Council\")"
      ],
      "metadata": {
        "id": "NHaJm0nJaPdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_df = city_df.withColumnRenamed(\"Settlement_Council\", \"Settlement_Council_Hebrew\")\n",
        "city_df = city_df.withColumnRenamed(\"City Name\", \"Settlement_Council\")"
      ],
      "metadata": {
        "id": "b-H5ruXjdhCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df5.collect()[100000] ## show specific row"
      ],
      "metadata": {
        "id": "m1GFtwe_37bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df5.show()"
      ],
      "metadata": {
        "id": "lswWB69tcpAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df5.printSchema()"
      ],
      "metadata": {
        "id": "pnScov91Uxhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df5.write.parquet(\"/content/drive/MyDrive/BDP_Project/df5.parquet\")"
      ],
      "metadata": {
        "id": "OnOmRv0Fz_Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Analysis"
      ],
      "metadata": {
        "id": "uPEluTRgbQ-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = spark.read.parquet(\"/content/drive/MyDrive/BDP_Project/df5.parquet\")"
      ],
      "metadata": {
        "id": "33b5_GDh0IO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Tikim_City = df5.groupBy('Settlement_Council').sum('TikimSum')\n",
        "df_Tikim_City = df_Tikim_City.join(city_df, on='Settlement_Council', how='left')\n",
        "df_Tikim_City = df_Tikim_City.join(df5.select('Settlement_Council','City_Cluster_2019').distinct(),on='Settlement_Council', how='left')\n",
        "df_Tikim_City = df_Tikim_City.withColumn(\"Tikim by population\",col(\"sum(TikimSum)\")/ col(\"Population\"))\n",
        "df_Tikim_City = df_Tikim_City.sort(\"Tikim by population\",ascending=False)\n",
        "df_Tikim_City.select(\"Settlement_Council\",\"City_Cluster_2019\",\"Tikim by population\").show(10)"
      ],
      "metadata": {
        "id": "9g7s-2qxbXxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # If the cell below doesn't work, run this:\n",
        "!python -m pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "MdmaZp1tQUoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df_Tikim_City.toPandas()[\"Tikim by population\"]);"
      ],
      "metadata": {
        "id": "FFISMVtOP8qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Tikim_District = df5.groupBy('PoliceDistrict','Date Value').sum('TikimSum')"
      ],
      "metadata": {
        "id": "ejAd4npBkWLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_Tikim_District = df_Tikim_District.toPandas()"
      ],
      "metadata": {
        "id": "lVNjiA3zd1BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "districts = pd.unique(pd_Tikim_District['PoliceDistrict'])\n",
        "for d in districts:\n",
        "  pd_district = pd_Tikim_District[pd_Tikim_District['PoliceDistrict'] == d]\n",
        "  pd_district = pd_district.sort_values(by = 'Date Value')\n",
        "  plt.plot(pd_district['Date Value'],pd_district['sum(TikimSum)'])\n",
        "plt.legend(districts, loc=\"upper left\")\n",
        "plt.axvline(x=datetime.date(2020,4,8), color='black', linestyle='dashed')\n",
        "plt.axvline(x=datetime.date(2021,3,31), color='black', linestyle='dashed')\n",
        "plt.ylim([0,25000])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Emv9ewxNltPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tikim_district = df5.groupBy('PoliceDistrict','StatisticCrimeGroup','Date Value').sum('TikimSum')"
      ],
      "metadata": {
        "id": "FReR4XuuFZz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "district = [\"Southern District\", \"Judea and Samaria District\", \"Jerusalem District\", \"North District\", \"Beach district\", \"Central district\", \"Tel Aviv District\"]\n",
        "for i in range(7):\n",
        "  pd_tikim_district = df_tikim_district.where(df_tikim_district.PoliceDistrict == district[i]).toPandas()\n",
        "  types = pd.unique(pd_tikim_district['StatisticCrimeGroup'])\n",
        "  types = np.delete(types, np.where(types == \"Nan\"))\n",
        "  for t in types:\n",
        "    pd_type = pd_tikim_district[pd_tikim_district['StatisticCrimeGroup'] == t]\n",
        "    pd_type = pd_type.sort_values(by = 'Date Value')\n",
        "    plt.plot(pd_type['Date Value'],pd_type['sum(TikimSum)'])\n",
        "  plt.legend(types, loc = \"upper left\")\n",
        "  plt.axvline(x=datetime.date(2020,4,8), color='black', linestyle='dashed')\n",
        "  plt.axvline(x=datetime.date(2021,3,31), color='black', linestyle='dashed')\n",
        "  plt.title(district[i])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "On1CwJmWI_JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Establishing \"Crime Score\""
      ],
      "metadata": {
        "id": "MYW2895Febyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crime_types = df5.select('StatisticCrimeGroup').distinct()\n",
        "crime_types = crime_types.withColumn('Score',col('StatisticCrimeGroup'))\n",
        "df5.select('StatisticCrimeGroup').distinct().show(17,False)"
      ],
      "metadata": {
        "id": "Z-PQ2yntpY3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crime_scores = {'The rest of the offenses':'1', 'Traffic violations': '2', 'Nan': '3', 'Permitted offenses': '1', 'Offenses against a person':'5', 'Confidence offenses': '3', 'Sex offenses': '5',\\\n",
        "                'Administrative offenses': '1', 'Economic offenses': '2', 'Public order offenses': '1', 'Offenses toward property': '3','Setup Sections': '1',\\\n",
        "                'Fraudulent offenses': '3','Offenses against body': '5','Offenses toward morality': '4','Unknown': '3', 'The rest of the rest': '1'}\n",
        "crime_types_score = crime_types.replace(crime_scores,subset=['Score'])\n",
        "crime_types_score.sort('Score',ascending=False).show(17,False)\n"
      ],
      "metadata": {
        "id": "eICUdvyMRpUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P = $ the population number of the city\n",
        "\n",
        "$n_i = $ number of specific crime group cases\n",
        "\n",
        "$S_i = $ the score of the specific crime group\n",
        "\n",
        "$$CrimeScore = \\frac{1}{P}\\sum_{i}{n_{i}\\cdot S_{i}}$$"
      ],
      "metadata": {
        "id": "MXMiCPrvifd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = df5.join(crime_types_score, on='StatisticCrimeGroup', how='left')\n",
        "df6 = df6.withColumn(\"Total_Score\",col(\"TikimSum\") * col(\"Score\"))\n",
        "df6 = df6.groupBy('Settlement_Council').sum('Total_Score')\n",
        "df_score_city = df5.join(df6, on='Settlement_Council', how='left')\n",
        "df_score_city = df_score_city.withColumn(\"Score per population\",col(\"sum(Total_Score)\") / col(\"Population\"))"
      ],
      "metadata": {
        "id": "azqIPQIt1MgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_city.select(\"Settlement_Council\",'City_Cluster_2019',\"Score per population\").distinct().sort(\"Score per population\",ascending=False).show(10)"
      ],
      "metadata": {
        "id": "UIcgqsKR4zNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_score_city.select('Settlement_Council','Population').filter(df_score_city.Population.isNull()).distinct().show(100)"
      ],
      "metadata": {
        "id": "5dRB2lFH797D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_score = df_score_city.select('Settlement_Council','City_Cluster_2019','Score per population').distinct().toPandas()\n",
        "sns.regplot(pd_score['City_Cluster_2019'],pd_score['Score per population'],ci=0,line_kws={\"color\": \"red\"})"
      ],
      "metadata": {
        "id": "zvXAdDpd71Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(pd_score['Score per population']);"
      ],
      "metadata": {
        "id": "h5QMAg0vPEem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$N = $ overall number of cases in the city \n",
        "\n",
        "$n_i = $ number of specific crime group cases\n",
        "\n",
        "$S_i = $ the score of the specific crime group\n",
        "\n",
        "$$CrimeScore = \\frac{1}{N}\\sum_{i}{n_{i}\\cdot S_{i}}$$"
      ],
      "metadata": {
        "id": "bIvm73tVf2SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = df5.join(crime_types_score, on='StatisticCrimeGroup', how='left')\n",
        "df7 = df7.withColumn(\"Total_Score\",col(\"TikimSum\") * col(\"Score\"))\n",
        "df8 = df7.groupBy('Settlement_Council').sum('Total_Score')\n",
        "df9 = df7.groupBy('Settlement_Council').sum('TikimSum')\n",
        "df_score_city2 = df9.join(df8, on='Settlement_Council', how='left')\n",
        "df_score_city2 = df_score_city2.withColumn(\"Score per population2\",col(\"sum(Total_Score)\") / col(\"sum(TikimSum)\"))"
      ],
      "metadata": {
        "id": "91_hzObB_5F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_city2.select(\"Settlement_Council\",\"Score per population2\").distinct().sort(\"Score per population2\",ascending=False).show(10)"
      ],
      "metadata": {
        "id": "gS3H8SKeAqXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_city2 = df_score_city2.join(df5.select('Settlement_Council','City_Cluster_2019'), on='Settlement_Council', how='left')"
      ],
      "metadata": {
        "id": "dxk3_pLHBXTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_score2 = df_score_city2.select('Settlement_Council','City_Cluster_2019','Score per population2').distinct().toPandas()\n",
        "sns.regplot(pd_score2['City_Cluster_2019'],pd_score2['Score per population2'],ci=0,line_kws={\"color\": \"red\"})"
      ],
      "metadata": {
        "id": "Gx3wJedBBX0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P = $ the population number of the city\n",
        "\n",
        "$N = $ overall number of cases in the city \n",
        "\n",
        "$n_i = $ number of specific crime group cases\n",
        "\n",
        "$S_i = $ the score of the specific crime group\n",
        "\n",
        "$$CrimeScore = \\frac{1}{2} \\cdot (\\frac{1}{P}\\sum_{i}{n_{i}\\cdot S_{i}} + \\frac{1}{N}\\sum_{i}{n_{i}\\cdot S_{i}})$$\n"
      ],
      "metadata": {
        "id": "oHMBDqLiQm3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft1 = df_score_city.select(\"Settlement_Council\",\"Score per population\",'City_Cluster_2019').distinct()\n",
        "dft2 = df_score_city2.select(\"Settlement_Council\",\"Score per population2\").distinct()\n",
        "df_score_city3 = dft1.join(dft2, on=\"Settlement_Council\", how=\"left\")\n",
        "df_score_city3 = df_score_city3.withColumn(\"Average Crime Score\",(col(\"Score per population\") + col(\"Score per population2\"))/2)\n",
        "pd_score3 = df_score_city3.select('Settlement_Council', 'City_Cluster_2019','Average Crime Score').distinct().toPandas()\n",
        "sns.regplot(pd_score3['City_Cluster_2019'],pd_score3['Average Crime Score'],ci=0,line_kws={\"color\": \"red\"})"
      ],
      "metadata": {
        "id": "bkTqf2e3Oi3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(pd_score3['Average Crime Score']);"
      ],
      "metadata": {
        "id": "zaTsbFusedwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_city3.select(\"Settlement_Council\",\"City_Cluster_2019\",\"Average Crime Score\").distinct().sort(\"Average Crime Score\",ascending=False).show(10)"
      ],
      "metadata": {
        "id": "PQld6n2veoeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deeper analysis and prediction"
      ],
      "metadata": {
        "id": "B7txVhQwjBXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building data that will fit prediction over time.\n",
        "years = ['2017', '2018', '2019', '2020', '2021', '2022']\n",
        "quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
        "df_ml = df5.select(\"Settlement_Council\",\"Population\",\"City_Cluster_2019\").distinct().dropna()\n",
        "for year in years:\n",
        "  for q in quarters:\n",
        "    if year == '2022' and q == 'Q4': # Skipping because there is no data for this time\n",
        "      break\n",
        "    year_q = year+\"_\"+q\n",
        "    df_by_time = df5.groupBy('Settlement_Council','year','Q').sum('TikimSum')\n",
        "    df_by_time = df_by_time.withColumnRenamed('sum(TikimSum)',year_q)\n",
        "    df_temp = df_by_time.where(df_by_time.year == year)\n",
        "    df_temp = df_temp.where(df_by_time.Q == q)\n",
        "    df_ml = df_ml.join(df_temp.select('Settlement_Council',year_q),on='Settlement_Council', how='left')"
      ],
      "metadata": {
        "id": "n0uUhr_x2zXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml.show(5)"
      ],
      "metadata": {
        "id": "5MY0CnqJ_DTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_columns = df_ml.columns[3:-1] # Removing the city name and the last quarter of 2022 (\"2022-Q3\") from the training columns"
      ],
      "metadata": {
        "id": "NIGz-1vixZC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a feature vector by combining the columns\n",
        "df_ml = df_ml.dropna()\n",
        "vector_assembler = VectorAssembler(inputCols=training_columns, outputCol=\"features\", handleInvalid=\"keep\")\n",
        "df_ml_vec = vector_assembler.transform(df_ml)"
      ],
      "metadata": {
        "id": "q5FDP6d5vMfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "df_ml_data = df_ml_vec.select(\"Settlement_Council\",\"features\",\"2022_Q3\")\n",
        "training_data, testing_data = df_ml_data.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "zSMuHszwvRVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the linear regression model\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"2022_Q3\")\n",
        "model = lr.fit(training_data)"
      ],
      "metadata": {
        "id": "-aSRhiJgy6Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to make predictions on the testing data\n",
        "predictions = model.transform(testing_data)\n",
        "predictions.show(5)"
      ],
      "metadata": {
        "id": "kQA3Y1jY0LWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_eval = RegressionEvaluator(predictionCol='prediction', labelCol='2022_Q3', metricName='r2')\n",
        "reg_eval.evaluate(predictions)"
      ],
      "metadata": {
        "id": "OKuAAkWvmqjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2023 = df_ml.dropna()\n",
        "training_columns = df_ml.columns[4:] # Now we will look at data data from one quarter later to adjust the model.\n",
        "vector_assembler_2023 = VectorAssembler(inputCols=training_columns, outputCol=\"features\" ,handleInvalid=\"keep\")\n",
        "df_2023 = vector_assembler_2023.transform(df_2023).select(\"Settlement_Council\",\"features\",\"2022_Q3\")\n",
        "predictions_2023 = model.transform(df_2023)"
      ],
      "metadata": {
        "id": "noFKyR8xHYlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_2023 = predictions_2023.withColumn(\"Crime Increase\",(col(\"prediction\")-col(\"2022_Q3\"))/col(\"2022_Q3\"))"
      ],
      "metadata": {
        "id": "cx6xKAhrJIU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_2023 = predictions_2023.join(df5.select(\"Settlement_Council\",\"City_Cluster_2019\").distinct(), on=\"Settlement_Council\", how=\"left\")"
      ],
      "metadata": {
        "id": "SYMW3TIVYRa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The cities with the predicted crime increase for 2023:\")\n",
        "predictions_2023.sort(\"Crime Increase\",ascending=False).select(\"Settlement_Council\",\"City_Cluster_2019\",\"Crime Increase\").show()"
      ],
      "metadata": {
        "id": "aKAnXoTcKbqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The cities with the predicted crime decrease for 2023:\")\n",
        "predictions_2023.sort(\"Crime Increase\",ascending=True).select(\"Settlement_Council\",\"City_Cluster_2019\",\"Crime Increase\").show()"
      ],
      "metadata": {
        "id": "p0a5aKyectMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Close spark session"
      ],
      "metadata": {
        "id": "3HhGXovmmz_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "nbngjjhtm1uf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}